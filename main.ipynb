{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SwfV3OMCiqG",
    "outputId": "a58c776f-7897-4d67-b426-d759e400ff8e"
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow_io\n",
    "%pip install -q kaggle\n",
    "%pip install resampy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSxJUvohJ_cL",
    "outputId": "f2ee0dad-6535-4876-ab45-241ccff00811"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8NEp5GsAIOk"
   },
   "outputs": [],
   "source": [
    "! mkdir -p ~/.kaggle\n",
    "!cp -p drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json\n",
    "!wget https://raw.githubusercontent.com/jackgle/YAMNet-transfer-learning/main/datagen_yamnet.py --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvFnCp_UCrSF"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d soumendraprasad/musical-instruments-sound-dataset\n",
    "!unzip -xq musical-instruments-sound-dataset.zip -d ./dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKvgTlWwDoJF"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/yamnet.zip ./yamnet.zip\n",
    "!unzip -xq yamnet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "en04-EMKCUv7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.sys.path.insert(0, yamnet_path)\n",
    "from params import Params as params_ds\n",
    "import features as features_lib\n",
    "import shutil\n",
    "import numpy as np\n",
    "import resampy\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import yamnet\n",
    "from datagen_yamnet import DataGenerator, get_files_and_labels\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uh3l4_avHF0T",
    "outputId": "8eb40ead-3905-4b7e-d28e-e8f2c333c92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sound_Drum', 'Sound_Guitar', 'Sound_Piano', 'Sound_Violin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=pd.read_csv(\"dataset/Metadata_Train.csv\")\n",
    "# df2=pd.read_csv(\"dataset/Metadata_Test.csv\")\n",
    "# classes=list(df['Class'].unique())\n",
    "classes=list(os.listdir(\"dataset_emb/train\"))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SLABvZTpQ5KW"
   },
   "outputs": [],
   "source": [
    "def to_dataset():\n",
    "  dataset_p=\"/content/dataset_/\"\n",
    "  os.makedirs(dataset_p,exist_ok=True)\n",
    "  shutil.rmtree(dataset_p)\n",
    "  def fn(base_p,dst_p,df_):\n",
    "    \n",
    "    for i in classes:\n",
    "      os.makedirs(dst_p+i,exist_ok=True)\n",
    "    for fn,c in tqdm(df_.values):\n",
    "      if c=='Sound_Guiatr':c='Sound_Guitar'\n",
    "      # shutil.copy(base_p+fn,dst_p+c+)\n",
    "      wav_data, sr = sf.read(base_p+fn, dtype=np.int16)\n",
    "      assert wav_data.dtype == np.int16, 'Bad sample type: %r' % wav_data.dtype\n",
    "      waveform = wav_data / 32768.0\n",
    "      \n",
    "      if len(waveform.shape) > 1:\n",
    "          waveform = waveform[:,0] # get left channel if multi-channel\n",
    "      if sr != params_ds.sample_rate:\n",
    "          waveform = resampy.resample(waveform, sr, params_ds.sample_rate)\n",
    "          \n",
    "      waveform = np.reshape(waveform, [1, -1]).astype(np.float32)\n",
    "      _, patches = features_lib.waveform_to_log_mel_spectrogram_patches(tf.squeeze(waveform, axis=0), params_ds)\n",
    "      np.save(dst_p+c+'/'+fn+'.npy', patches)\n",
    "    \n",
    "  #train\n",
    "  train_base='/content/dataset/Train_submission/Train_submission/'\n",
    "  train_dst=dataset_p+'train/'\n",
    "  fn(train_base,train_dst,df)\n",
    "  #test\n",
    "  test_base='/content/dataset/Test_submission/Test_submission/'\n",
    "  test_dst=dataset_p+\"test/\"\n",
    "  fn(test_base,test_dst,df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZrJgARHH_Fb"
   },
   "outputs": [],
   "source": [
    "to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJvdjBPLKpCp"
   },
   "outputs": [],
   "source": [
    "!cp -rf drive/MyDrive/dataset_/ dataset_/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0sEuvj0VIot"
   },
   "outputs": [],
   "source": [
    "!cp -rf drive/MyDrive/dataset_emb/ dataset_emb/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VKkKgbK3WAaX"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/audioset/yamnet.h5 -q\n",
    "weights_path='./yamnet.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4XPctQt7gdVm"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IxqnduasKakE"
   },
   "outputs": [],
   "source": [
    "import params\n",
    "params = params.Params()   \n",
    "# del yamnet_model   \n",
    "weights_path='./yamnet.h5'                \n",
    "yamnet_model = yamnet.yamnet_frames_model(params)\n",
    "yamnet_model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFnMzdPSNYZM"
   },
   "outputs": [],
   "source": [
    "def make_embedings():\n",
    "  dataset_p=\"/content/dataset_emb/\"\n",
    "  os.makedirs(dataset_p,exist_ok=True)\n",
    "  shutil.rmtree(dataset_p)\n",
    "  def covert_to_int16(filename):\n",
    "      wav_data, sr = sf.read(filename, dtype=np.int16)\n",
    "      sf.write(filename,wav_data,sr)\n",
    "  def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    covert_to_int16(filename)\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "  def fn(base_p,dst_p,df_):\n",
    "    for i in classes:\n",
    "      os.makedirs(dst_p+i,exist_ok=True)\n",
    "    for fn,c in tqdm(df_.values):\n",
    "      if c=='Sound_Guiatr':c='Sound_Guitar'\n",
    "      # shutil.copy(base_p+fn,dst_p+c+)\n",
    "      wav_data=load_wav_16k_mono(base_p+fn)\n",
    "      predictions, embeddings, log_mel_spectrogram = yamnet_model(wav_data)\n",
    "      np.save(dst_p+c+'/emb_'+fn+'.npy', embeddings)\n",
    "\n",
    "  \n",
    "  train_base='/content/dataset/Train_submission/Train_submission/'\n",
    "  train_dst=dataset_p+'train/'\n",
    "  fn(train_base,train_dst,df)\n",
    "  #test\n",
    "  test_base='/content/dataset/Test_submission/Test_submission/'\n",
    "  test_dst=dataset_p+\"test/\"\n",
    "  fn(test_base,test_dst,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdkBRVzkRRiU"
   },
   "outputs": [],
   "source": [
    "make_embedings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qMhTg8fSjmrh"
   },
   "outputs": [],
   "source": [
    "\n",
    "def x():\n",
    "\n",
    "  def fn(path):\n",
    "    ls_=[]\n",
    "    for c in os.listdir(path):\n",
    "      for name in os.listdir(f'{path}/{c}'):\n",
    "        ls_.append((f'{path}{c}/{name}',c))\n",
    "    return ls_\n",
    "  p=\"dataset_emb/train/\"\n",
    "  train_df=pd.DataFrame(fn(p))\n",
    "  train_df.to_csv(\"dataset_emb/train_files.csv\",index=False)\n",
    "\n",
    "  p=\"dataset_emb/test/\"\n",
    "  test_df=pd.DataFrame(fn(p))\n",
    "  test_df.to_csv(\"dataset_emb/test_files.csv\",index=False)\n",
    "\n",
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FR9DdxMtWI8q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"yamnet_base\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 96, 64)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 96, 64, 1)         0         \n",
      "                                                                 \n",
      " layer1/conv (Conv2D)        (None, 48, 32, 32)        288       \n",
      "                                                                 \n",
      " layer1/conv/bn (BatchNormal  (None, 48, 32, 32)       96        \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " layer1/relu (ReLU)          (None, 48, 32, 32)        0         \n",
      "                                                                 \n",
      " layer2/depthwise_conv (Dept  (None, 48, 32, 32)       288       \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer2/depthwise_conv/bn (B  (None, 48, 32, 32)       96        \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer2/depthwise_conv/relu   (None, 48, 32, 32)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer2/pointwise_conv (Conv  (None, 48, 32, 64)       2048      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer2/pointwise_conv/bn (B  (None, 48, 32, 64)       192       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer2/pointwise_conv/relu   (None, 48, 32, 64)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer3/depthwise_conv (Dept  (None, 24, 16, 64)       576       \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer3/depthwise_conv/bn (B  (None, 24, 16, 64)       192       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer3/depthwise_conv/relu   (None, 24, 16, 64)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer3/pointwise_conv (Conv  (None, 24, 16, 128)      8192      \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer3/pointwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer3/pointwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer4/depthwise_conv (Dept  (None, 24, 16, 128)      1152      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer4/depthwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer4/depthwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer4/pointwise_conv (Conv  (None, 24, 16, 128)      16384     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer4/pointwise_conv/bn (B  (None, 24, 16, 128)      384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer4/pointwise_conv/relu   (None, 24, 16, 128)      0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer5/depthwise_conv (Dept  (None, 12, 8, 128)       1152      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer5/depthwise_conv/bn (B  (None, 12, 8, 128)       384       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer5/depthwise_conv/relu   (None, 12, 8, 128)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer5/pointwise_conv (Conv  (None, 12, 8, 256)       32768     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer5/pointwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer5/pointwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer6/depthwise_conv (Dept  (None, 12, 8, 256)       2304      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer6/depthwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer6/depthwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer6/pointwise_conv (Conv  (None, 12, 8, 256)       65536     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer6/pointwise_conv/bn (B  (None, 12, 8, 256)       768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer6/pointwise_conv/relu   (None, 12, 8, 256)       0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer7/depthwise_conv (Dept  (None, 6, 4, 256)        2304      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer7/depthwise_conv/bn (B  (None, 6, 4, 256)        768       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer7/depthwise_conv/relu   (None, 6, 4, 256)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer7/pointwise_conv (Conv  (None, 6, 4, 512)        131072    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer7/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer7/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer8/depthwise_conv (Dept  (None, 6, 4, 512)        4608      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer8/depthwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer8/depthwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer8/pointwise_conv (Conv  (None, 6, 4, 512)        262144    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer8/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer8/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer9/depthwise_conv (Dept  (None, 6, 4, 512)        4608      \n",
      " hwiseConv2D)                                                    \n",
      "                                                                 \n",
      " layer9/depthwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer9/depthwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer9/pointwise_conv (Conv  (None, 6, 4, 512)        262144    \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " layer9/pointwise_conv/bn (B  (None, 6, 4, 512)        1536      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " layer9/pointwise_conv/relu   (None, 6, 4, 512)        0         \n",
      " (ReLU)                                                          \n",
      "                                                                 \n",
      " layer10/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer10/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer10/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer10/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer10/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer10/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer11/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer11/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer11/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer11/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer11/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer11/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer12/depthwise_conv (Dep  (None, 6, 4, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer12/depthwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer12/depthwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer12/pointwise_conv (Con  (None, 6, 4, 512)        262144    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer12/pointwise_conv/bn (  (None, 6, 4, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer12/pointwise_conv/relu  (None, 6, 4, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer13/depthwise_conv (Dep  (None, 3, 2, 512)        4608      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer13/depthwise_conv/bn (  (None, 3, 2, 512)        1536      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer13/depthwise_conv/relu  (None, 3, 2, 512)        0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer13/pointwise_conv (Con  (None, 3, 2, 1024)       524288    \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer13/pointwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer13/pointwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer14/depthwise_conv (Dep  (None, 3, 2, 1024)       9216      \n",
      " thwiseConv2D)                                                   \n",
      "                                                                 \n",
      " layer14/depthwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer14/depthwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " layer14/pointwise_conv (Con  (None, 3, 2, 1024)       1048576   \n",
      " v2D)                                                            \n",
      "                                                                 \n",
      " layer14/pointwise_conv/bn (  (None, 3, 2, 1024)       3072      \n",
      " BatchNormalization)                                             \n",
      "                                                                 \n",
      " layer14/pointwise_conv/relu  (None, 3, 2, 1024)       0         \n",
      "  (ReLU)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,217,344\n",
      "Trainable params: 3,195,456\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.Model(yamnet_model.get_layer('reshape').input,\n",
    "                                   yamnet_model.get_layer('global_average_pooling2d').output,\n",
    "                                   name='yamnet_base')\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3ym8j5FNWUG3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_yamnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 96, 64)]          0         \n",
      "                                                                 \n",
      " yamnet_base (Functional)    (None, 1024)              3217344   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,349,060\n",
      "Trainable params: 3,327,172\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (int(params.patch_window_seconds/params.stft_hop_seconds),\n",
    "               params.mel_bands)\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    \n",
    "    # call the base model\n",
    "    # set batch norm layers to inference mode\n",
    "    # https://keras.io/guides/transfer_learning/\n",
    "    x = base_model(inputs, training=False)\n",
    "    \n",
    "    # define model top\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x) \n",
    "\n",
    "    # x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(len(classes), activation='softmax')(x)\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.models.Model(inputs, outputs, name='custom_yamnet')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qd5qgZGQXoqX"
   },
   "outputs": [],
   "source": [
    "train_dir = './dataset_emb/train/'\n",
    "files_train, files_val, labels = get_files_and_labels(train_dir, \n",
    "                                                    typ='npy',\n",
    "                                                    train_split=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2MQdNNfHWbUX"
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "train_generator = DataGenerator(files_train,\n",
    "                                labels,\n",
    "                                n_classes=len(classes),\n",
    "                                batch_size=batch_size)\n",
    "validation_generator = DataGenerator(files_val,\n",
    "                                    labels,\n",
    "                                    n_classes=len(classes),\n",
    "                                    batch_size=batch_size)\n",
    "\n",
    "model_out=\"models/model_y\"\n",
    "# define training callbacks\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(model_out+'.h5',\n",
    "                                                 monitor='val_loss', \n",
    "                                                 verbose=1,\n",
    "                                                 save_best_only=True, \n",
    "                                                 mode='auto')\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min', min_lr=0.0001)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log', separator=',', append=False)\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwerNL0goL4I"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NIbKC91uKNif"
   },
   "outputs": [],
   "source": [
    "num_classes=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-6A3OSQHOfP"
   },
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNPPd0EZgp6a"
   },
   "outputs": [],
   "source": [
    "model.get_layer('yamnet_base').trainable = False\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer,metrics=[keras.metrics.categorical_accuracy,])\n",
    "\n",
    "model_history = model.fit(train_generator,\n",
    "                            steps_per_epoch = len(train_generator),\n",
    "                            epochs = 12,\n",
    "                            validation_data = validation_generator,\n",
    "                            validation_steps = len(validation_generator),\n",
    "                            verbose = 1,\n",
    "                            callbacks=[checkpoint,\n",
    "early_stop,\n",
    "\n",
    "checkpoint,\n",
    "reduce_lr,\n",
    "tensorboard,\n",
    "csv_logger,\n",
    "lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D13ZLg69FnD-"
   },
   "outputs": [],
   "source": [
    "!cp -rfp ./dataset_emb drive/MyDrive/dataset_emb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PIQlqeEMiAeD"
   },
   "source": [
    "# training of saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9u6Fl531iE5z"
   },
   "outputs": [],
   "source": [
    "train_df_emb=pd.read_csv('dataset_emb/train_files.csv')\n",
    "test_df_emb=pd.read_csv('dataset_emb/test_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X6yQlvtrnr_z"
   },
   "outputs": [],
   "source": [
    "train_df_emb = train_df_emb.sample(frac=1)\n",
    "test_df_emb = test_df_emb.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT8rhORHy2zw",
    "outputId": "c01aae72-1a2b-403c-de39-31bf16a117ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "zkDtpC5i3NDc"
   },
   "outputs": [],
   "source": [
    "\n",
    "my_model=Sequential([\n",
    "    # Dense(1024,activation='relu',),\n",
    "    keras.layers.Dense(128, input_shape=(1024,),activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    Dense(4,activation='softmax'),\n",
    "])\n",
    "from keras.losses import categorical_crossentropy\n",
    "my_model.compile(loss=categorical_crossentropy,metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5clHRl_c4CIQ",
    "outputId": "1a193308-805c-417f-8518-eb05b510ded4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131,716\n",
      "Trainable params: 131,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3_m9croL5PFW"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def to_ds(t):\n",
    "  # print(t)\n",
    "  f_n,c=t\n",
    "  emb=np.load(f_n).astype(\"float32\")\n",
    "  one_c=to_categorical(classes.index(c),len(classes))\n",
    "  num_emb=emb.shape[0]\n",
    "  return emb,np.tile(one_c, (num_emb, 1))\n",
    "   \n",
    "Xy=train_df_emb.apply(to_ds,axis=1)\n",
    "Xy_t=test_df_emb.apply(to_ds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cbSAuIJnTpXT"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "for i,j in Xy:\n",
    "  for x_ in i:\n",
    "    X.append(x_)\n",
    "  for y_ in j:\n",
    "    y.append(y_)\n",
    "X=np.array(X,dtype='float32')\n",
    "y=np.array(y,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t=[]\n",
    "y_t=[]\n",
    "for i,j in Xy_t:\n",
    "  for x_ in i:\n",
    "    X_t.append(x_)\n",
    "  for y_ in j:\n",
    "    y_t.append(y_)\n",
    "X_t=np.array(X_t,dtype='float32')\n",
    "y_t=np.array(y_t,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRBC4tkKTZMM",
    "outputId": "6cd6bc83-7b38-45b9-9cd9-8944de09835c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96688, 1024), (96688, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3965, 1024), (3965, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape,y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KjWi9BxgeNfE"
   },
   "outputs": [],
   "source": [
    "data_size=X.shape[0]\n",
    "split_ind=int(data_size*.85)\n",
    "X_train,y_train=X[:split_ind],y[:split_ind]\n",
    "X_val,y_val=X[split_ind:],y[split_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "A4mZjdyoffJm"
   },
   "outputs": [],
   "source": [
    "model_out=\"models/model_y_emb\"\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=1, )\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=0.00001)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "csv_logger = keras.callbacks.CSVLogger('training.log', separator=',', append=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0K2_GQ--X0f",
    "outputId": "1dde7770-e79f-4e50-f2f4-856f829c31e8"
   },
   "outputs": [],
   "source": [
    "hist=my_model.fit(X,y,batch_size=32,epochs=20,validation_data=(X_val,y_val),shuffle=True,callbacks=[checkpoint,\n",
    "early_stop,\n",
    "checkpoint,\n",
    "reduce_lr,\n",
    "tensorboard,\n",
    "csv_logger,\n",
    "],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 1s 4ms/step - loss: 1.2753 - categorical_accuracy: 0.7269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2753185033798218, 0.7268600463867188]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=my_model.evaluate(X_t,y_t) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4504392"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_top/assets\n"
     ]
    }
   ],
   "source": [
    "my_model.save('best_top/',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    eval = my_model.evaluate(X_t,y_t,verbose=-1)\n",
    "    pred = my_model.predict(X_t,verbose=-1)\n",
    "    pred_mean = np.mean(pred,axis=0,dtype='float32')\n",
    "    pred_dict={j:float(i) for i,j in zip(pred_mean,classes_key)}\n",
    "    # exp=np.exp(pred_mean)\n",
    "    # pred_softmax=exp/np.sum(exp)\n",
    "    rows.append([f_n,c,classes_key[pred_mean.argmax()],eval[1],eval[0],*pred_mean])\n",
    "    res.append((f_n,c,eval,pred_dict))\n",
    "    df=pd.DataFrame(rows ,columns=['filename','actual_class','predicted_class','eval_scroe',\"eval_loss\",'Sound_Drum','Sound_Guitar',\"Sound_Piano\",\"Sound_Violin\"])\n",
    "    df.to_csv(\"res.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = my_model.evaluate(X_t,y_t,verbose=-1)\n",
    "pred = my_model.predict(X_t,verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame(pred, columns =classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['actual_class']=y_t.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"pred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Sound_Drum       0.80      0.79      0.80       900\n",
      "Sound_Guitar       0.94      0.67      0.78      1619\n",
      " Sound_Piano       0.68      0.93      0.78      1139\n",
      "Sound_Violin       0.09      0.11      0.10       307\n",
      "\n",
      "    accuracy                           0.73      3965\n",
      "   macro avg       0.63      0.62      0.61      3965\n",
      "weighted avg       0.77      0.73      0.73      3965\n",
      "\n",
      "{'Sound_Drum': {'precision': 0.801354401805869, 'recall': 0.7888888888888889, 'f1-score': 0.7950727883538634, 'support': 900}, 'Sound_Guitar': {'precision': 0.9408695652173913, 'recall': 0.6683137739345275, 'f1-score': 0.7815095702419645, 'support': 1619}, 'Sound_Piano': {'precision': 0.6784338896020539, 'recall': 0.9280070237050044, 'f1-score': 0.7838338895068594, 'support': 1139}, 'Sound_Violin': {'precision': 0.0889487870619946, 'recall': 0.10749185667752444, 'f1-score': 0.09734513274336284, 'support': 307}, 'accuracy': 0.7268600252206809, 'macro avg': {'precision': 0.6274016609218271, 'recall': 0.6231753858014862, 'f1-score': 0.6144403452115125, 'support': 3965}, 'weighted avg': {'precision': 0.7678512649677202, 'recall': 0.7268600252206809, 'f1-score': 0.732282789316707, 'support': 3965}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_test = np.argmax(y_t, axis=1) # Convert one-hot to index\n",
    "y_pred = np.argmax(pred,axis=1)\n",
    "print(classification_report(Y_test, y_pred,target_names=classes))\n",
    "print(classification_report(Y_test, y_pred,output_dict=True,target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Sound_Piano': 195,\n",
       "         'Sound_Guitar': 46,\n",
       "         'Sound_Violin': 33,\n",
       "         'Sound_Drum': 33})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i,j in zip(y_pred,Y_test):\n",
    "    if (j==3):#Sound_Violin\n",
    "        l.append(classes[i])\n",
    "from collections import Counter\n",
    "Counter(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{#violin miss prediction of classes \n",
    "#these are the prediction for violin class predictions\n",
    "'Sound_Piano': 195,\n",
    "'Sound_Guitar': 46,\n",
    "'Sound_Violin': 33,\n",
    "'Sound_Drum': 33\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96688, 1024)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sound_Drum</th>\n",
       "      <th>Sound_Guitar</th>\n",
       "      <th>Sound_Piano</th>\n",
       "      <th>Sound_Violin</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.801354</td>\n",
       "      <td>0.940870</td>\n",
       "      <td>0.678434</td>\n",
       "      <td>0.088949</td>\n",
       "      <td>0.72686</td>\n",
       "      <td>0.627402</td>\n",
       "      <td>0.767851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.668314</td>\n",
       "      <td>0.928007</td>\n",
       "      <td>0.107492</td>\n",
       "      <td>0.72686</td>\n",
       "      <td>0.623175</td>\n",
       "      <td>0.726860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.795073</td>\n",
       "      <td>0.781510</td>\n",
       "      <td>0.783834</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.72686</td>\n",
       "      <td>0.614440</td>\n",
       "      <td>0.732283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>1619.000000</td>\n",
       "      <td>1139.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>0.72686</td>\n",
       "      <td>3965.000000</td>\n",
       "      <td>3965.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sound_Drum  Sound_Guitar  Sound_Piano  Sound_Violin  accuracy  \\\n",
       "precision    0.801354      0.940870     0.678434      0.088949   0.72686   \n",
       "recall       0.788889      0.668314     0.928007      0.107492   0.72686   \n",
       "f1-score     0.795073      0.781510     0.783834      0.097345   0.72686   \n",
       "support    900.000000   1619.000000  1139.000000    307.000000   0.72686   \n",
       "\n",
       "             macro avg  weighted avg  \n",
       "precision     0.627402      0.767851  \n",
       "recall        0.623175      0.726860  \n",
       "f1-score      0.614440      0.732283  \n",
       "support    3965.000000   3965.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Sound_Drum': {'precision': 0.801354401805869, 'recall': 0.7888888888888889, 'f1-score': 0.7950727883538634, 'support': 900}, 'Sound_Guitar': {'precision': 0.9408695652173913, 'recall': 0.6683137739345275, 'f1-score': 0.7815095702419645, 'support': 1619}, 'Sound_Piano': {'precision': 0.6784338896020539, 'recall': 0.9280070237050044, 'f1-score': 0.7838338895068594, 'support': 1139}, 'Sound_Violin': {'precision': 0.0889487870619946, 'recall': 0.10749185667752444, 'f1-score': 0.09734513274336284, 'support': 307}, 'accuracy': 0.7268600252206809, 'macro avg': {'precision': 0.6274016609218271, 'recall': 0.6231753858014862, 'f1-score': 0.6144403452115125, 'support': 3965}, 'weighted avg': {'precision': 0.7678512649677202, 'recall': 0.7268600252206809, 'f1-score': 0.732282789316707, 'support': 3965}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
